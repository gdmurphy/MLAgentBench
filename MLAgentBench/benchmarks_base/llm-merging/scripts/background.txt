Model merging is increasingly recognized as an efficient approach to enhance models without extensive retraining. Two primary applications of this technique are: (1) combining model checkpoints that differ in data versions, hyperparameters, or training stages to improve robustness across data distributions, and (2) integrating multiple specialized models, each trained on unique datasets, to benefit from their complementary strengths. In both cases, the models typically share a common architecture and originate from a single base model fine-tuned for specific tasks.

This study focuses on merging fine-tuned models (experts) derived from the same base model to enhance its functionality. Each expert is trained on a distinct dataset covering specific tasks, domains, or capabilities. We categorize the tasks or datasets used for training these experts as "held-in," while unseen or novel tasks are labeled "held-out." Our goal is to create a unified model that preserves the expertise of individual models on held-in tasks while enhancing its zero-shot generalization to held-out tasks. This merging strategy provides a modular, post-training method to improve large language models, allowing new features and capabilities to be seamlessly added.

---

### Model Merging Methods

Letâ€™s denote the tasks for the experts as \( t_1, t_2, \ldots, t_N \), the base model weights as \( \theta_\text{base} \), and the weights of the expert models fine-tuned for specific tasks as \( \theta_1, \ldots, \theta_N \). The merged model's parameters \( \theta_m \) are computed using a merging function \( \mathcal{M} \). This function takes as input the base model, the expert models, and potentially some additional information (\( \Phi \)), such as activation statistics or Fisher matrices. Formally, 
\[ \theta_m = \mathcal{M}(\{\theta_i\}_{i=1}^N, \theta_\text{base}, \Phi), \]
where \( \Phi \) represents method-specific data.

Given the focus on scaling merging techniques to large models, this study evaluates four methods that are efficient for models with billions of parameters and do not require additional information (\( \Phi = \{\} \)). We exclude more complex methods, such as those involving Fisher matrices, backward passes, or activation statistics, due to their computational overhead. The four selected methods are described below:

---

#### Averaging
Parameter averaging is a straightforward technique widely used in federated learning and has been adapted for various purposes, such as enhancing robustness to out-of-distribution data, refining pre-trained models, and developing multitask models. The method computes the mean of all expert model weights without using the base model:
\[ 
\mathcal{M}(\{\theta_i\}_{i=1}^N, \theta_\text{base}) = \frac{1}{N} \sum_{i=1}^N \theta_i. 
\]

---

#### Task Arithmetic
Task Arithmetic introduces the concept of "task vectors" to capture task-specific knowledge. For a task \( t_i \), the task vector is \( \tau_i = \theta_i - \theta_\text{base} \). The merged model is constructed by combining the base model parameters with a scaled sum of the task vectors:
\[ 
\mathcal{M}(\{\theta_i\}_{i=1}^N, \theta_\text{base}; \lambda) = \theta_\text{base} + \lambda \sum_{i=1}^N (\theta_i - \theta_\text{base}). 
\]

---

#### TIES Merging
TIES Merging addresses two challenges in model merging: noise accumulation during fine-tuning and conflicts between parameter updates in different expert models. The method involves three steps: (1) trimming task vectors by zeroing out low-magnitude values, (2) resolving sign conflicts by determining an aggregate sign for each parameter, and (3) averaging only the non-conflicting parameters. The merged task vector is then scaled and added to the base model:
\[ 
\theta_m^p = \theta_\text{base} + \lambda \frac{1}{|\mathcal{A}^p|} \sum_{i \in \mathcal{A}^p} \hat{\tau}_i^p, 
\]
where \( \mathcal{A}^p \) is the set of non-conflicting task vectors for parameter \( p \).

---

#### Dare Merging
Dare extends TIES Merging by introducing a dropout-like mechanism to prune noise from task vectors. A Bernoulli mask with drop probability \( p \) is applied to the task vectors to create pruned versions:
\[ 
\hat{\tau}_i = (1 - M_i) \odot \tau_i / (1 - p). 
\]
These pruned vectors are then used in conjunction with TIES Merging to produce the final merged model.

---

This modular approach to model merging enables efficient post-training improvements, offering a practical solution for scaling large language models with new capabilities.


#### Reference
[1] Yadav, P., Vu, T., Lai, J., Chronopoulou, A., Faruqui, M., Bansal, M., & Munkhdalai, T. (2024). What Matters for Model Merging at Scale?. arXiv preprint arXiv:2410.03617.
