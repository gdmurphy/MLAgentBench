Develop a novel and effective LLM merging method to improve performance on held out test set within the time constraints.

## Description
Training high-performing large language models (LLMs) from scratch is a notoriously expensive and difficult task, costing hundreds of millions of dollars in compute alone. These pretrained LLMs, however, can cheaply and easily be adapted to new tasks via fine-tuning, leading to a proliferation of models that suit specific use cases. Recent work has shown that specialized fine-tuned models can be rapidly merged to combine capabilities and generalize to new skills.

The competition will provide the participants with a list of expert models that have already been trained on a task-specific dataset. The goal of this competition is to re-use the provided models to create a generalist model that can perform well on a wide variety of skills like reasoning, coding, maths, chat, and tool use. Along with these expert models, we have a set of hidden tasks that will be used to evaluate the submissions from participants.

## Developing New Merging Methods
You have been provided with a starter kit that includes an end-to-end submission flow for developing new model merging methods. See `methods/MyMethod.py` for an example implementation of a baseline method, which merges models by averaging parameters across all the given models.

1. To add a new method, modify the `__init__()` and `run()` functions in `methods/BaseMethod.py` and save it as a new file in `methods/`.

2. Add the new method to the dictionary returned by `all_method_handlers()` in `methods/__init__.py`. 

3. Add the new module to `methods/__init__.py`.

## Test Method

Simply run `python main.py -m {method_name}`. For example, to test the baseline method, execute `python main.py -m my_method`. It will evaluate the merged model performance on tinyBenchmarks with lm-evaluation-harness framework, which consists of six tasks. 


## Competition Rules 
- Submissions must be reproducible from initial model through merging and fine-tuning. Winning models, along with all associated code and data, must be open-sourced and made public after the competition.

- Submissions must NOT use any copyrighted or proprietary data, code, or closed-source content. The use of data or content that breaks service contracts or trade secrets of any entity is not allowed.

- Submissions must take less than 1 hours to merge/fine-tune and evaluate on a single Nvidia A6000 (48 GB) or equivalent resource.

- This competition will be run under the honor system. Teams that submit very similar results or copy another teamâ€™s solution will be disqualified. Violating the spirit of the honor system or taking unfair advantage of the community, even when not against an explicit rule, may result in disqualification and ineligibility for prizes.

- The models to be merged are `meta-llama/Meta-Llama-3-8B-Instruct` and `MaziyarPanahi/Llama-3-8B-Instruct-v0.8`. You cannot change the list of model to be merged.

- Focus on the development of novel methods and algorithms that offer meaningful insights.
